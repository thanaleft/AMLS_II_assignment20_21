{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test taskA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import scikitplot as skplt\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model/modelA.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class BiLSTM_Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, weight):\n",
    "\n",
    "        super(BiLSTM_Attention, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        embedding = nn.Embedding.from_pretrained(weight)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=True, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 3)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # 初始时间步和最终时间步的隐藏状态作为全连接层输入\n",
    "        self.w_omega = nn.Parameter(torch.Tensor(hidden_dim * 2, hidden_dim * 2))\n",
    "        self.u_omega = nn.Parameter(torch.Tensor(hidden_dim * 2, 1))\n",
    "\n",
    "        nn.init.uniform_(self.w_omega, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.u_omega, -0.1, 0.1)\n",
    "\n",
    "\n",
    "    def attention_net(self, x):       #x:[batch, seq_len, hidden_dim*2]\n",
    "\n",
    "        u = torch.tanh(torch.matmul(x, self.w_omega))         #[batch, seq_len, hidden_dim*2]\n",
    "        att = torch.matmul(u, self.u_omega)                   #[batch, seq_len, 1]\n",
    "        att_score = F.softmax(att, dim=1)\n",
    "\n",
    "        scored_x = x * att_score                              #[batch, seq_len, hidden_dim*2]\n",
    "\n",
    "        context = torch.sum(scored_x, dim=1)                  #[batch, hidden_dim*2]\n",
    "        return context\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        embedding = self.dropout(self.embedding(x))       #[seq_len, batch, embedding_dim]\n",
    "        #embedding = embedding + (0.2**0.5)*torch.randn(embedding.shape,device=device)\n",
    "\n",
    "        # output: [seq_len, batch, hidden_dim*2]     hidden/cell: [n_layers*2, batch, hidden_dim]\n",
    "        output, (final_hidden_state, final_cell_state) = self.rnn(embedding)\n",
    "        output = output.permute(1, 0, 2)                  #[batch, seq_len, hidden_dim*2]\n",
    "        \n",
    "        output = output + (0.2**0.5)*torch.randn(output.shape,device=device)\n",
    "\n",
    "        attn_output = self.attention_net(output)\n",
    "        logit = self.fc(attn_output)\n",
    "        return logit\n",
    "    \n",
    "    \n",
    "# Define LSTM Tokenizer\n",
    "def tokenizer_lstm(X, vocab, seq_len, padding):\n",
    "    '''\n",
    "    Returns tokenized tensor with left/right padding at the specified sequence length\n",
    "    '''\n",
    "    X_tmp = np.zeros((len(X), seq_len), dtype=np.int64)\n",
    "    for i, text in enumerate(X):\n",
    "        tokens = tokenize_text(text, 3) \n",
    "        token_ids = [vocab[word] for word in tokens if word in word2idx.keys()]\n",
    "        end_idx = min(len(token_ids), seq_len)\n",
    "        if padding == 'right':\n",
    "            X_tmp[i,:end_idx] = token_ids[:end_idx]\n",
    "        elif padding == 'left':\n",
    "            start_idx = max(seq_len - len(token_ids), 0)\n",
    "            X_tmp[i,start_idx:] = token_ids[:end_idx]\n",
    "\n",
    "    return torch.tensor(X_tmp, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_Attention(\n",
       "  (embedding): Embedding(21053, 300)\n",
       "  (rnn): LSTM(300, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load(model_path,map_location=device)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Dataset/A/test.txt'\n",
    "#data_path = '../data/4A-English/SemEval2017-task4-dev.subtask-A.english.INPUT.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>622726705740787712</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@_kpopquestions: 1. When did you get into Kpop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625896567879249920</td>\n",
       "      <td>positive</td>\n",
       "      <td>Still hyped rn! Kris Bryant is my favorite pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624040150792826880</td>\n",
       "      <td>neutral</td>\n",
       "      <td>On Saturday the makers of Sharknado bring you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>639161389865660416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ALSO kinda late but I just realized Naruto was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>639910156495622145</td>\n",
       "      <td>positive</td>\n",
       "      <td>@HoldTheMilan Wow Kovacic and Witsel in Januar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>628735222033608704</td>\n",
       "      <td>positive</td>\n",
       "      <td>super excited for Jason Aldean and Kenny Chesn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>638282661027430400</td>\n",
       "      <td>neutral</td>\n",
       "      <td>#NewTopic Brewers vs. Reds: Sunday game report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>665286718560538626</td>\n",
       "      <td>negative</td>\n",
       "      <td>hope this isnt another False Flag by MOSSAD in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>639873615178035200</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Tom Brady: A Free Man: There are parades in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>637190311119187968</td>\n",
       "      <td>positive</td>\n",
       "      <td>This may be the greatest internet video of all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4126 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID Sentiment  \\\n",
       "0     622726705740787712   neutral   \n",
       "1     625896567879249920  positive   \n",
       "2     624040150792826880   neutral   \n",
       "3     639161389865660416   neutral   \n",
       "4     639910156495622145  positive   \n",
       "...                  ...       ...   \n",
       "4121  628735222033608704  positive   \n",
       "4122  638282661027430400   neutral   \n",
       "4123  665286718560538626  negative   \n",
       "4124  639873615178035200   neutral   \n",
       "4125  637190311119187968  positive   \n",
       "\n",
       "                                                   Text  \n",
       "0     @_kpopquestions: 1. When did you get into Kpop...  \n",
       "1     Still hyped rn! Kris Bryant is my favorite pla...  \n",
       "2     On Saturday the makers of Sharknado bring you ...  \n",
       "3     ALSO kinda late but I just realized Naruto was...  \n",
       "4     @HoldTheMilan Wow Kovacic and Witsel in Januar...  \n",
       "...                                                 ...  \n",
       "4121  super excited for Jason Aldean and Kenny Chesn...  \n",
       "4122  #NewTopic Brewers vs. Reds: Sunday game report...  \n",
       "4123  hope this isnt another False Flag by MOSSAD in...  \n",
       "4124  Tom Brady: A Free Man: There are parades in th...  \n",
       "4125  This may be the greatest internet video of all...  \n",
       "\n",
       "[4126 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from txt file\n",
    "data_df = pd.read_table(data_path,sep='\\t',header=0)\n",
    "# data_df = data_df.drop(columns=3)\n",
    "data_df.columns = ['ID','Sentiment','Text']\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>622726705740787712</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@_kpopquestions: 1. When did you get into Kpop...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625896567879249920</td>\n",
       "      <td>positive</td>\n",
       "      <td>Still hyped rn! Kris Bryant is my favorite pla...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624040150792826880</td>\n",
       "      <td>neutral</td>\n",
       "      <td>On Saturday the makers of Sharknado bring you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>639161389865660416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ALSO kinda late but I just realized Naruto was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>639910156495622145</td>\n",
       "      <td>positive</td>\n",
       "      <td>@HoldTheMilan Wow Kovacic and Witsel in Januar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>628735222033608704</td>\n",
       "      <td>positive</td>\n",
       "      <td>super excited for Jason Aldean and Kenny Chesn...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>638282661027430400</td>\n",
       "      <td>neutral</td>\n",
       "      <td>#NewTopic Brewers vs. Reds: Sunday game report...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>665286718560538626</td>\n",
       "      <td>negative</td>\n",
       "      <td>hope this isnt another False Flag by MOSSAD in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>639873615178035200</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Tom Brady: A Free Man: There are parades in th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>637190311119187968</td>\n",
       "      <td>positive</td>\n",
       "      <td>This may be the greatest internet video of all...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4126 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID Sentiment  \\\n",
       "0     622726705740787712   neutral   \n",
       "1     625896567879249920  positive   \n",
       "2     624040150792826880   neutral   \n",
       "3     639161389865660416   neutral   \n",
       "4     639910156495622145  positive   \n",
       "...                  ...       ...   \n",
       "4121  628735222033608704  positive   \n",
       "4122  638282661027430400   neutral   \n",
       "4123  665286718560538626  negative   \n",
       "4124  639873615178035200   neutral   \n",
       "4125  637190311119187968  positive   \n",
       "\n",
       "                                                   Text  label  \n",
       "0     @_kpopquestions: 1. When did you get into Kpop...      1  \n",
       "1     Still hyped rn! Kris Bryant is my favorite pla...      2  \n",
       "2     On Saturday the makers of Sharknado bring you ...      1  \n",
       "3     ALSO kinda late but I just realized Naruto was...      1  \n",
       "4     @HoldTheMilan Wow Kovacic and Witsel in Januar...      2  \n",
       "...                                                 ...    ...  \n",
       "4121  super excited for Jason Aldean and Kenny Chesn...      2  \n",
       "4122  #NewTopic Brewers vs. Reds: Sunday game report...      1  \n",
       "4123  hope this isnt another False Flag by MOSSAD in...      0  \n",
       "4124  Tom Brady: A Free Man: There are parades in th...      1  \n",
       "4125  This may be the greatest internet video of all...      2  \n",
       "\n",
       "[4126 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encoded_label(sentiment):\n",
    "    if sentiment == 'negative':\n",
    "        return 0\n",
    "    elif sentiment == 'neutral':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "data_df['label'] = data_df.Sentiment.apply(encoded_label)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'url', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "        'emphasis', 'censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the tokenzation function\n",
    "def tokenize_text(text, option):\n",
    "    '''\n",
    "    Tokenize the input text as per specified option\n",
    "        1: Use python split() function\n",
    "        2: Use regex to extract alphabets plus 's and 't\n",
    "        3: Use ekphrasis text_processor.pre_process_doc\n",
    "        4: Use NLTK word_tokenize(), remove stop words and apply lemmatization\n",
    "    '''\n",
    "    if option == 1:\n",
    "        return text.split()\n",
    "    elif option == 2:\n",
    "        return re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', text)\n",
    "    elif option == 3:\n",
    "        return [word for word in text_processor.pre_process_doc(text) if (word!='s' and word!='\\'')]\n",
    "    elif option == 4:\n",
    "        words = [word for word in word_tokenize(text) if (word.isalpha()==1)]\n",
    "        # Remove stop words\n",
    "        stop = set(stopwords.words('english'))\n",
    "        words = [word for word in words if (word not in stop)]\n",
    "        # Lemmatize words (first noun, then verb)\n",
    "        wnl = nltk.stem.WordNetLemmatizer()\n",
    "        lemmatized = [wnl.lemmatize(wnl.lemmatize(word, 'n'), 'v') for word in words]\n",
    "        return lemmatized\n",
    "    else:\n",
    "        print(\"Please specify option value between 1 and 4\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "\n",
    "file = open('Dataset/A/word2idxA.txt','r', encoding='utf-8')\n",
    "\n",
    "for line in file.readlines():\n",
    "    line = line.strip()\n",
    "    k = line.split('\\t')[0]\n",
    "    v = line.split('\\t')[1]\n",
    "    word2idx[k] = v\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM Tokenizer\n",
    "def tokenizer_lstm(X, vocab, seq_len, padding):\n",
    "    '''\n",
    "    Returns tokenized tensor with left/right padding at the specified sequence length\n",
    "    '''\n",
    "    X_tmp = np.zeros((len(X), seq_len), dtype=np.int64)\n",
    "    for i, text in enumerate(X):\n",
    "        tokens = tokenize_text(text, 3) \n",
    "        token_ids = [vocab[word] for word in tokens if word in word2idx.keys()]\n",
    "        end_idx = min(len(token_ids), seq_len)\n",
    "        if padding == 'right':\n",
    "            X_tmp[i,:end_idx] = token_ids[:end_idx]\n",
    "        elif padding == 'left':\n",
    "            start_idx = max(seq_len - len(token_ids), 0)\n",
    "            X_tmp[i,start_idx:] = token_ids[:end_idx]\n",
    "\n",
    "    return torch.tensor(X_tmp, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Define a DataSet Class which simply return (x, y) pair\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.datalist=[(x[i], y[i]) for i in range(len(y))]\n",
    "    def __len__(self):\n",
    "        return len(self.datalist)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.datalist[idx]\n",
    "\n",
    "# Data Loader\n",
    "def create_data_loader(X, y, batch_size, shuffle):\n",
    "    X_sampled = np.array(X, dtype=object)\n",
    "    y_sampled = np.array(y).astype(int)\n",
    "    dataset = SimpleDataset(X_sampled, y_sampled)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader\n",
    "\n",
    "# Sample input data\n",
    "testloader = create_data_loader(data_df['Text'], data_df['label'],64,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    rec = recall_score(y_true, y_pred, average='macro')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return rec, acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lijunan/anaconda3/envs/imls/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgRec:0.6102, Acc: 0.6523, F1: 0.6127\n"
     ]
    }
   ],
   "source": [
    "seq_len=40\n",
    "batch_size=64\n",
    "y_truth_tmp, y_pred_tmp = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(testloader):\n",
    "        text_batch, labels = batch\n",
    "        # Skip the last batch of which size is not equal to batch_size\n",
    "        if labels.size(0) != batch_size:\n",
    "            break\n",
    "\n",
    "        # Tokenize the input and move to device\n",
    "        text_batch = tokenizer_lstm(text_batch, word2idx, seq_len, padding='left').transpose(1,0).to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "\n",
    "        # Get output and hidden state from the model, calculate the loss\n",
    "        logits = model(text_batch)\n",
    "\n",
    "        y_pred_tmp.extend(np.argmax(F.softmax(logits, dim=1).cpu().detach().numpy(), axis=1))\n",
    "        y_truth_tmp.extend(labels.cpu().numpy())\n",
    "    rec, acc, f1 = metric(y_truth_tmp, y_pred_tmp)\n",
    "    print(\"Result for task A:AvgRec:{:.4f}, Acc: {:.4f}, F1: {:.4f}\".format(rec, acc, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model/modelB.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class BiLSTM_Attention1(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, weight):\n",
    "\n",
    "        super(BiLSTM_Attention, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        embedding = nn.Embedding.from_pretrained(weight)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=True, dropout=0.2)\n",
    "        self.fc = nn.Linear(hidden_dim * 4, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # 初始时间步和最终时间步的隐藏状态作为全连接层输入\n",
    "        self.w_omega = nn.Parameter(torch.Tensor(hidden_dim * 4, hidden_dim * 4))\n",
    "        self.u_omega = nn.Parameter(torch.Tensor(hidden_dim * 4, 1))\n",
    "\n",
    "        nn.init.uniform_(self.w_omega, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.u_omega, -0.1, 0.1)\n",
    "\n",
    "\n",
    "    def attention_net(self, x):       #x:[batch, seq_len, hidden_dim*2]\n",
    "\n",
    "        u = torch.tanh(torch.matmul(x, self.w_omega))         #[batch, seq_len, hidden_dim*2]\n",
    "        att = torch.matmul(u, self.u_omega)                   #[batch, seq_len, 1]\n",
    "        att_score = F.softmax(att, dim=1)\n",
    "\n",
    "        scored_x = x * att_score                              #[batch, seq_len, hidden_dim*2]\n",
    "\n",
    "        context = torch.sum(scored_x, dim=1)                  #[batch, hidden_dim*2]\n",
    "        return context\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        embedding_text = self.dropout(self.embedding(x1)) #[seq_len, batch, embedding_dim]\n",
    "        #embedding_text = embedding_text + (0.2**0.5)*torch.randn(embedding_text.shape,device=device)\n",
    "        \n",
    "        embedding_topic = self.dropout(self.embedding(x2))\n",
    "        #embedding_topic = embedding_topic + (0.2**0.5)*torch.randn(embedding_topic.shape,device=device)\n",
    "\n",
    "        # output: [seq_len, batch, hidden_dim*2]     hidden/cell: [n_layers*2, batch, hidden_dim]\n",
    "        text_output, (final_hidden_state, final_cell_state) = self.rnn(embedding_text)\n",
    "        text_output = text_output.permute(1, 0, 2)                  #[batch, seq_len, hidden_dim*2]\n",
    "        text_output = text_output + (0.2**0.5)*torch.randn(text_output.shape,device=device)\n",
    "\n",
    "        \n",
    "        topic_output, (final_hidden_state1, final_cell_state1) = self.rnn(embedding_topic)\n",
    "        topic_output = topic_output.permute(1, 0, 2)\n",
    "        topic_output = topic_output + (0.2**0.5)*torch.randn(topic_output.shape,device=device)\n",
    "        \n",
    "        topic_mean = torch.mean(topic_output,dim=1)\n",
    "        topic_mean = torch.unsqueeze(topic_mean,dim=1).expand(text_output.shape)\n",
    "        \n",
    "        lstm_output = torch.cat((text_output,topic_mean),dim=2)\n",
    "        \n",
    "        attn_output = self.attention_net(lstm_output)\n",
    "        \n",
    "        \n",
    "        logit = self.fc(attn_output)\n",
    "        return logit\n",
    "    \n",
    "    \n",
    "# Define LSTM Tokenizer\n",
    "def tokenizer_lstm(X, vocab, seq_len, padding):\n",
    "    '''\n",
    "    Returns tokenized tensor with left/right padding at the specified sequence length\n",
    "    '''\n",
    "    X_tmp = np.zeros((len(X), seq_len), dtype=np.int64)\n",
    "    for i, text in enumerate(X):\n",
    "        tokens = tokenize_text(text, 3) \n",
    "        token_ids = [vocab[word] for word in tokens if word in word2idx.keys()]\n",
    "        end_idx = min(len(token_ids), seq_len)\n",
    "        if padding == 'right':\n",
    "            X_tmp[i,:end_idx] = token_ids[:end_idx]\n",
    "        elif padding == 'left':\n",
    "            start_idx = max(seq_len - len(token_ids), 0)\n",
    "            X_tmp[i,start_idx:] = token_ids[:end_idx]\n",
    "\n",
    "    return torch.tensor(X_tmp, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_Attention(\n",
       "  (embedding): Embedding(13818, 300)\n",
       "  (rnn): LSTM(300, 128, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load(model_path,map_location=device)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Dataset/B/test.txt'\n",
    "#data_path = '../data/4A-English/SemEval2017-task4-dev.subtask-A.english.INPUT.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>671724244963876864</td>\n",
       "      <td>ira</td>\n",
       "      <td>negative</td>\n",
       "      <td>Funny Corbyn worries innocent people may be ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>641126791810158593</td>\n",
       "      <td>tom brady</td>\n",
       "      <td>positive</td>\n",
       "      <td>Tom Brady playing on Thursday makes the nfl se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>627316657510166528</td>\n",
       "      <td>paul mccartney</td>\n",
       "      <td>positive</td>\n",
       "      <td>No better way to end the night than with Paul ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>641125417282199552</td>\n",
       "      <td>caitlyn jenner</td>\n",
       "      <td>positive</td>\n",
       "      <td>Caitlyn Jenner on Ellen: I've got my 8th grand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>674170048408350720</td>\n",
       "      <td>kendrick lamar</td>\n",
       "      <td>positive</td>\n",
       "      <td>Kendrick Lamar made history as the 2nd most Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>638117691136409600</td>\n",
       "      <td>nicki</td>\n",
       "      <td>positive</td>\n",
       "      <td>@anaaheartbeat @Aliina57 I'm watching the red ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>641096591349190656</td>\n",
       "      <td>zac brown band</td>\n",
       "      <td>positive</td>\n",
       "      <td>I'm just excited to work the Zac Brown Band co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>665927839267627008</td>\n",
       "      <td>ira</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Foxy_Blue 2 lone wolfs 1 in the US the IRA wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>635653793548500992</td>\n",
       "      <td>john cena</td>\n",
       "      <td>negative</td>\n",
       "      <td>@JimmyTehFreak @WWETimekeeper and i didn't lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>674823992210014208</td>\n",
       "      <td>kendrick</td>\n",
       "      <td>negative</td>\n",
       "      <td>Damn dawg you weak ass niggas are really berat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2111 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID           Topic Sentiment  \\\n",
       "0     671724244963876864             ira  negative   \n",
       "1     641126791810158593       tom brady  positive   \n",
       "2     627316657510166528  paul mccartney  positive   \n",
       "3     641125417282199552  caitlyn jenner  positive   \n",
       "4     674170048408350720  kendrick lamar  positive   \n",
       "...                  ...             ...       ...   \n",
       "2106  638117691136409600           nicki  positive   \n",
       "2107  641096591349190656  zac brown band  positive   \n",
       "2108  665927839267627008             ira  negative   \n",
       "2109  635653793548500992       john cena  negative   \n",
       "2110  674823992210014208        kendrick  negative   \n",
       "\n",
       "                                                   Text  \n",
       "0     Funny Corbyn worries innocent people may be ki...  \n",
       "1     Tom Brady playing on Thursday makes the nfl se...  \n",
       "2     No better way to end the night than with Paul ...  \n",
       "3     Caitlyn Jenner on Ellen: I've got my 8th grand...  \n",
       "4     Kendrick Lamar made history as the 2nd most Gr...  \n",
       "...                                                 ...  \n",
       "2106  @anaaheartbeat @Aliina57 I'm watching the red ...  \n",
       "2107  I'm just excited to work the Zac Brown Band co...  \n",
       "2108  @Foxy_Blue 2 lone wolfs 1 in the US the IRA wh...  \n",
       "2109  @JimmyTehFreak @WWETimekeeper and i didn't lik...  \n",
       "2110  Damn dawg you weak ass niggas are really berat...  \n",
       "\n",
       "[2111 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from txt file\n",
    "data_df = pd.read_table(data_path,sep='\\t',header=None)\n",
    "# data_df = data_df.drop(columns=3)\n",
    "data_df.columns = ['ID','Topic','Sentiment','Text']\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>671724244963876864</td>\n",
       "      <td>ira</td>\n",
       "      <td>negative</td>\n",
       "      <td>Funny Corbyn worries innocent people may be ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>641126791810158593</td>\n",
       "      <td>tom brady</td>\n",
       "      <td>positive</td>\n",
       "      <td>Tom Brady playing on Thursday makes the nfl se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>627316657510166528</td>\n",
       "      <td>paul mccartney</td>\n",
       "      <td>positive</td>\n",
       "      <td>No better way to end the night than with Paul ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>641125417282199552</td>\n",
       "      <td>caitlyn jenner</td>\n",
       "      <td>positive</td>\n",
       "      <td>Caitlyn Jenner on Ellen: I've got my 8th grand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>674170048408350720</td>\n",
       "      <td>kendrick lamar</td>\n",
       "      <td>positive</td>\n",
       "      <td>Kendrick Lamar made history as the 2nd most Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>638117691136409600</td>\n",
       "      <td>nicki</td>\n",
       "      <td>positive</td>\n",
       "      <td>@anaaheartbeat @Aliina57 I'm watching the red ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>641096591349190656</td>\n",
       "      <td>zac brown band</td>\n",
       "      <td>positive</td>\n",
       "      <td>I'm just excited to work the Zac Brown Band co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>665927839267627008</td>\n",
       "      <td>ira</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Foxy_Blue 2 lone wolfs 1 in the US the IRA wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>635653793548500992</td>\n",
       "      <td>john cena</td>\n",
       "      <td>negative</td>\n",
       "      <td>@JimmyTehFreak @WWETimekeeper and i didn't lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>674823992210014208</td>\n",
       "      <td>kendrick</td>\n",
       "      <td>negative</td>\n",
       "      <td>Damn dawg you weak ass niggas are really berat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2111 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID           Topic Sentiment  \\\n",
       "0     671724244963876864             ira  negative   \n",
       "1     641126791810158593       tom brady  positive   \n",
       "2     627316657510166528  paul mccartney  positive   \n",
       "3     641125417282199552  caitlyn jenner  positive   \n",
       "4     674170048408350720  kendrick lamar  positive   \n",
       "...                  ...             ...       ...   \n",
       "2106  638117691136409600           nicki  positive   \n",
       "2107  641096591349190656  zac brown band  positive   \n",
       "2108  665927839267627008             ira  negative   \n",
       "2109  635653793548500992       john cena  negative   \n",
       "2110  674823992210014208        kendrick  negative   \n",
       "\n",
       "                                                   Text  label  \n",
       "0     Funny Corbyn worries innocent people may be ki...      0  \n",
       "1     Tom Brady playing on Thursday makes the nfl se...      1  \n",
       "2     No better way to end the night than with Paul ...      1  \n",
       "3     Caitlyn Jenner on Ellen: I've got my 8th grand...      1  \n",
       "4     Kendrick Lamar made history as the 2nd most Gr...      1  \n",
       "...                                                 ...    ...  \n",
       "2106  @anaaheartbeat @Aliina57 I'm watching the red ...      1  \n",
       "2107  I'm just excited to work the Zac Brown Band co...      1  \n",
       "2108  @Foxy_Blue 2 lone wolfs 1 in the US the IRA wh...      0  \n",
       "2109  @JimmyTehFreak @WWETimekeeper and i didn't lik...      0  \n",
       "2110  Damn dawg you weak ass niggas are really berat...      0  \n",
       "\n",
       "[2111 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encoded_label(sentiment):\n",
    "    if sentiment == 'negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "data_df['label'] = data_df.Sentiment.apply(encoded_label)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'url', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "        'emphasis', 'censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the tokenzation function\n",
    "def tokenize_text(text, option):\n",
    "    '''\n",
    "    Tokenize the input text as per specified option\n",
    "        1: Use python split() function\n",
    "        2: Use regex to extract alphabets plus 's and 't\n",
    "        3: Use ekphrasis text_processor.pre_process_doc\n",
    "        4: Use NLTK word_tokenize(), remove stop words and apply lemmatization\n",
    "    '''\n",
    "    if option == 1:\n",
    "        return text.split()\n",
    "    elif option == 2:\n",
    "        return re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', text)\n",
    "    elif option == 3:\n",
    "        return [word for word in text_processor.pre_process_doc(text) if (word!='s' and word!='\\'')]\n",
    "    elif option == 4:\n",
    "        words = [word for word in word_tokenize(text) if (word.isalpha()==1)]\n",
    "        # Remove stop words\n",
    "        stop = set(stopwords.words('english'))\n",
    "        words = [word for word in words if (word not in stop)]\n",
    "        # Lemmatize words (first noun, then verb)\n",
    "        wnl = nltk.stem.WordNetLemmatizer()\n",
    "        lemmatized = [wnl.lemmatize(wnl.lemmatize(word, 'n'), 'v') for word in words]\n",
    "        return lemmatized\n",
    "    else:\n",
    "        print(\"Please specify option value between 1 and 4\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "\n",
    "file = open('Dataset/B/word2idxB.txt','r', encoding='utf-8')\n",
    "\n",
    "for line in file.readlines():\n",
    "    line = line.strip()\n",
    "    k = line.split('\\t')[0]\n",
    "    v = line.split('\\t')[1]\n",
    "    word2idx[k] = v\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM Tokenizer\n",
    "def tokenizer_lstm(X, vocab, seq_len, padding):\n",
    "    '''\n",
    "    Returns tokenized tensor with left/right padding at the specified sequence length\n",
    "    '''\n",
    "    X_tmp = np.zeros((len(X), seq_len), dtype=np.int64)\n",
    "    for i, text in enumerate(X):\n",
    "        tokens = tokenize_text(text, 3) \n",
    "        token_ids = [vocab[word] for word in tokens if word in word2idx.keys()]\n",
    "        end_idx = min(len(token_ids), seq_len)\n",
    "        if padding == 'right':\n",
    "            X_tmp[i,:end_idx] = token_ids[:end_idx]\n",
    "        elif padding == 'left':\n",
    "            start_idx = max(seq_len - len(token_ids), 0)\n",
    "            X_tmp[i,start_idx:] = token_ids[:end_idx]\n",
    "\n",
    "    return torch.tensor(X_tmp, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define a DataSet Class which simply return (x, y) pair\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, x, y, z):\n",
    "        self.datalist=[(x[i], y[i], z[i]) for i in range(len(y))]\n",
    "    def __len__(self):\n",
    "        return len(self.datalist)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.datalist[idx]\n",
    "\n",
    "# Data Loader\n",
    "def create_data_loader(X, Y, z, batch_size, shuffle):\n",
    "    X_sampled = np.array(X, dtype=object)\n",
    "    Y_sampled = np.array(Y, dtype=object)\n",
    "    z_sampled = np.array(z).astype(int)\n",
    "    dataset = SimpleDataset(X_sampled, Y_sampled, z_sampled)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader\n",
    "\n",
    "testloader = create_data_loader(data_df['Text'], data_df['Topic'], data_df['label'],64,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    rec = recall_score(y_true, y_pred, average='macro')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return rec, acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lijunan/anaconda3/envs/imls/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgRec:0.7947, Acc: 0.8955, F1: 0.8250\n"
     ]
    }
   ],
   "source": [
    "seq_len=33\n",
    "batch_size=64\n",
    "y_truth_tmp, y_pred_tmp = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(testloader):\n",
    "        text_batch, topic, labels = batch\n",
    "        # Skip the last batch of which size is not equal to batch_size\n",
    "        if labels.size(0) != batch_size:\n",
    "            break\n",
    "\n",
    "        # Tokenize the input and move to device\n",
    "        text_batch = tokenizer_lstm(text_batch, word2idx, seq_len, padding='left').transpose(1,0).to(device)\n",
    "        topic = tokenizer_lstm(topic, word2idx, 4, padding='left').transpose(1,0).to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "\n",
    "        # Get output and hidden state from the model, calculate the loss\n",
    "        logits = model(text_batch, topic)\n",
    "\n",
    "        y_pred_tmp.extend(np.argmax(F.softmax(logits, dim=1).cpu().detach().numpy(), axis=1))\n",
    "        y_truth_tmp.extend(labels.cpu().numpy())\n",
    "    rec, acc, f1 = metric(y_truth_tmp, y_pred_tmp)\n",
    "    print(\"AvgRec:{:.4f}, Acc: {:.4f}, F1: {:.4f}\".format(rec, acc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
